# CE-FEDL
Communication Efficient (CE) - Federated Learning (FEDL)

This project aims to compare different methods by each participant against each other on the same two datasets.
The main focus is to reduce the communication overhead, which is a common problem with federated learning.

The goal is to reduce the communication while keeping the performance and results as balanced as possible.

The methods are:
- Federated Distillation
- A choice of different aggregation methods
- personalization
- Compression methods (especially sparsification)
